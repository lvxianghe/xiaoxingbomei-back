# 大模型应用开发

## 一、导言

在短时间内掌握前沿 AI 应用技术，从传统开发者转型为下一代智能系统构建者

1. （是什么）大模型、Prompt、RAG、多模态、Function Calling、MCP，你想要的前沿知识这里都有！

2. （为什么要做）大模型应用开发能带来什么？

3. （怎么做）只有python才能干AI？Java完全没问题！架构设计+完整实践，干货统统奉上！

   

## 二、理论基础

### （是什么）大模型应用技术脉络，通俗易懂

```
（大模型是怎么来的可以自行去了解，这里侧重关心基于大模型的能力去升级应用的能力）

1. 传统应用："从已有的数据中找到想要的内容"

2. 大模型（Model）：一颗聪明的大脑，能够理解和生成人类语言，"根据提示生成可能的内容"

3. 提示词（Prompt）：，通过预设或者用户每次发送的内容作为大模型的输入，影响生成内容走向

4. 嵌入（Embeddings）：将文本、图像视频等用数字表示，转换成向量

5. 令牌（token）：输入给模型的内容会先转为token，输出也是由token转为内容。（在英语中，一个标记大约相当于一个单词的 75%。作为参考，莎士比亚全集总计约 900,000 字，翻译成大约 120 万个token）

6. 记忆（Memory）：模型虽然聪明，但本身不具备记忆功能

6. 检索增强生成（RAG）：以更低成本的方式，帮助大模型生成更高质量（知识量、知识时效）的回答

7. 多模态（Multimodality）：帮助大模型具备读懂和生成更丰富内容的能力，如图片、音视频等

8. 工具调用（Function tool）：帮助大模型 从 "说出来" 到 "动起来"

9. 模型上下文协议（MCP）：统一的方式，让大模型"动起来"

在大模型的应用开发领域，一步步走来，大模型从最开始的"聪明大脑"变成一个能说会道、有记忆、可以学习新知识且能做实事的"智能体"
```

### （为什么要做）大模型应用开发的价值

```
Agent即智能体
让大模型"代理/模拟"「人」的行为，使用某些"工具/功能"来完成某些"任务"

Agent能做的事情，在Agent出现之前其实就能做

能带来的好处是什么呢？
1.降低应用开发门槛：无论是写代码、剪辑、还是音视频创作等
2.简化流程复杂度：区别于传统开发严丝合缝的流程编排，通过大模型强大的理解能力大大的降低流程的构建复杂度
3.交互方式多样性：agent不局限于自然语言交互，还有多种比如图形界面和动作执行的交互（比如代理操作浏览器）
4.协同完成复杂任务，多个不同的agent进行 组装、协同、竞争，共同参与决策进行合作，达到更好的效果

不像是传统系统各方面最佳实践已经成型，目前使用大模型构建Agent诸多挑战，如响应速度慢、幻觉和纯文本交互不优友好等
1.提升响应速度：芯片提升、模型参数裁剪、模型蒸馏、输入内容预处理（文档切块、Prompt压缩等）
2.降低幻觉：引导Prompt规范书写、慢思考、GraphRAG、Agent预编译
3.其他
```

### （怎么做）大模型应用开发架构设计

#### 整体架构流程
```
用户 → 前端应用 → 大模型服务 → 工具层 → 外部系统
  ↑              ↓          ↑       ↓        ↓
  └─────── 响应展示 ←── AI回答 ←── 工具执行 ←── 数据获取
```

#### 核心模块设计
1. **模型管理层**：统一管理多种大模型（OpenAI、Ollama等）
2. **对话引擎**：处理用户输入，维护上下文记忆
3. **工具管理器**：动态发现和管理可用工具
4. **MCP协议层**：统一工具调用标准
5. **数据存储层**：聊天记录、向量数据、系统配置

### （怎么做）如何进行大模型应用开发

1. **大模型服务**：通过本地部署/云端获取大模型服务
   
   **图片生成提示词**：
   ```
   创建一个现代化的技术架构图，展示大模型服务的获取方式。图中包含：
   - 左侧：云端服务（OpenAI、Azure、百度等云平台图标）
   - 右侧：本地部署（Ollama、Docker容器）
   - 中间：Java Spring AI框架连接层
   - 底部：应用层（聊天界面、API接口）
   使用蓝色和绿色的现代化配色，简洁清晰的线条风格
   ```

2. **对话记忆管理**：让AI具备上下文记忆能力
   
   **图片生成提示词**：
   ```
   绘制对话记忆管理的流程图：
   - 用户输入消息气泡
   - 记忆存储组件（数据库图标）
   - 上下文检索模块
   - AI大脑处理中心
   - 回答生成输出
   用对话气泡和箭头展示信息流向，采用渐变色彩
   ```

3. **工具调用（Function Calling）**：让AI从"说"到"做"
   
   **图片生成提示词**：
   ```
   设计工具调用架构图：
   - 中心：AI大脑（机器人头像）
   - 周围环绕各种工具图标：天气API、数据库、文件系统、网络请求
   - 用齿轮和连接线表示工具调用流程
   - 底部显示执行结果反馈
   采用橙色和蓝色搭配，科技感十足
   ```

4. **MCP协议**：统一工具管理标准
   
   **图片生成提示词**：
   ```
   创建MCP协议架构示意图：
   - 上层：MCP Client（客户端管理器）
   - 下层：多个MCP Server（工具服务器）
   - 中间：MCP协议连接线
   - 右侧：工具注册表和健康监控
   使用分层架构风格，蓝绿渐变配色
   ```

5. **RAG检索增强生成**：知识库集成
   
   **图片生成提示词**：
   ```
   绘制RAG系统流程图：
   - 文档输入 → 向量化处理 → 向量数据库存储
   - 用户问题 → 相似性检索 → 相关知识片段
   - 知识片段 + 问题 → 大模型 → 增强回答
   用文档图标、向量点阵、搜索图标表示各环节
   ```

## 三、实践

### 1. 项目结构设计

```
xiaoxingbomei-back/
├── llm-common/          # 公共模块
├── llm-server/          # AI服务端（MCP Server）
├── llm-client/          # 客户端（MCP Client）
└── docs/               # 文档说明
```

### 2. 核心实现代码

#### 2.1 大模型配置管理
```java
// llm-server/src/main/java/org/xiaoxingbomei/config/llm/AiModelProperties.java
@ConfigurationProperties(prefix = "spring.ai")
@Component
public class AiModelProperties {
    private OpenAiModelConfig openai = new OpenAiModelConfig();
    private OllamaModelConfig ollama = new OllamaModelConfig();
    
    // 支持多种模型配置
    public static class OpenAiModelConfig {
        private String apiKey;
        private String baseUrl = "https://api.openai.com";
        private String model = "gpt-3.5-turbo";
    }
}
```

#### 2.2 工具注册与发现
```java
// llm-server/src/main/java/org/xiaoxingbomei/config/llm/McpToolConfig.java
@Configuration
public class McpToolConfig {
    
    @Bean
    @Description("获取天气信息")
    public Function<String, String> getWeather() {
        return city -> "天气API调用结果: " + city + "今天晴朗";
    }
    
    @Bean 
    @Description("查询数据库用户信息")
    public Function<String, String> queryUser() {
        return userId -> "用户信息: " + userId;
    }
}
```

#### 2.3 MCP客户端管理器
```java
// llm-client/src/main/java/org/xiaoxingbomei/config/McpClientManager.java
@Component
public class McpClientManager {
    
    @PostConstruct
    public void initializeMcpClient() {
        // 1. 注册MCP服务器
        registerMcpServer("weather-server", "http://localhost:28928", "工具服务器");
        
        // 2. 发现并注册工具
        discoverToolsFromServers();
        
        // 3. 打印工具摘要
        printMcpSummary();
    }
    
    private void discoverToolsFromServer(String serverName, McpServerInfo serverInfo) {
        String toolsUrl = serverInfo.getUrl() + "/mcp/tools";
        Map<String, Object> response = restTemplate.getForObject(toolsUrl, Map.class);
        
        // 解析工具列表并注册到本地
        // ...工具解析逻辑
    }
}
```

#### 2.4 对话服务核心逻辑
```java
// llm-server/src/main/java/org/xiaoxingbomei/service/impl/ChatServiceImpl.java
@Service
public class ChatServiceImpl implements ChatService {
    
    public LlmChatHistory chat(String message, String sessionId) {
        // 1. 构建聊天客户端（集成工具）
        ChatClient chatClient = chatClientBuilder
                .defaultSystem(getSystemPrompt())
                .defaultToolCallbacks(toolCallbackProvider)
                .build();
        
        // 2. 获取历史对话记忆
        List<Message> chatHistory = getChatHistory(sessionId);
        
        // 3. 执行对话（自动工具调用）
        String response = chatClient
                .prompt()
                .user(message)
                .messages(chatHistory)
                .call()
                .content();
        
        // 4. 保存对话记录
        saveChatHistory(sessionId, message, response);
        
        return new LlmChatHistory(message, response);
    }
}
```

#### 2.5 RESTful API接口
```java
// llm-server/src/main/java/org/xiaoxingbomei/controller/ChatController.java
@RestController
@RequestMapping("/chat")
public class ChatController {
    
    @PostMapping("/send")
    public GlobalResponse<LlmChatHistory> sendMessage(
            @RequestBody ChatRequest request) {
        
        LlmChatHistory response = chatService.chat(
            request.getMessage(), 
            request.getSessionId()
        );
        
        return Response_Utils.success(response);
    }
    
    @GetMapping("/history/{sessionId}")
    public GlobalResponse<List<LlmChatHistory>> getChatHistory(
            @PathVariable String sessionId) {
        
        return Response_Utils.success(
            chatService.getChatHistoryList(sessionId)
        );
    }
}
```

#### 2.6 MCP健康检查
```java
// llm-client/src/main/java/org/xiaoxingbomei/controller/McpClientController.java
@RestController
@RequestMapping("/mcp")
public class McpClientController {
    
    @GetMapping("/health")
    public GlobalResponse<Map<String, Object>> health() {
        Map<String, Object> healthStatus = mcpClientManager.getHealthStatus();
        return Response_Utils.success(healthStatus);
    }
    
    @GetMapping("/tools")
    public GlobalResponse<List<McpToolInfo>> getTools() {
        List<McpToolInfo> tools = mcpClientManager.getAllTools();
        return Response_Utils.success(tools);
    }
}
```

### 3. 快速启动示例

#### 3.1 配置文件
```yaml
# llm-server/src/main/resources/application-dev.yml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY:sk-your-key}
      base-url: ${OPENAI_BASE_URL:https://api.openai.com}
    ollama:
      base-url: http://localhost:11434
      
server:
  port: 28928
```

#### 3.2 启动命令
```bash
# 1. 启动MCP Server（工具提供方）
cd llm-server
mvn spring-boot:run

# 2. 启动MCP Client（工具管理方）
cd llm-client  
mvn spring-boot:run

# 3. 测试API
curl -X POST http://localhost:28928/chat/send \
  -H "Content-Type: application/json" \
  -d '{"message":"今天杭州天气如何？","sessionId":"test-001"}'
```

### 4. 核心特性总结

✅ **多模型支持**：OpenAI、Ollama等主流模型  
✅ **工具生态**：基于MCP协议的统一工具管理  
✅ **对话记忆**：会话级别的上下文保持  
✅ **健康监控**：实时监控工具和服务状态  
✅ **RESTful API**：完整的HTTP接口支持  
✅ **可扩展架构**：模块化设计，易于扩展新功能

通过这个实践项目，你将掌握从零构建企业级大模型应用的完整技能栈！





